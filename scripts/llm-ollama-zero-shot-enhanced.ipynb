{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e75e4497",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "from pydantic import BaseModel\n",
    "import subprocess\n",
    "import gc\n",
    "import pandas as pd\n",
    "import json\n",
    "from icecream import ic\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0bc662d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ones installed on my pc\n",
    "model_names = [\n",
    "    \"llama3.1\",\n",
    "    # \"olmo-3:7b-instruct\",\n",
    "    # \"olmo-3\",        # Cannot disable the thinking here but it's essentially the preivous one\n",
    "    # \"granite3.3\",\n",
    "    # \"ministral-3\",\n",
    "    # \"qwen3\",\n",
    "    # \"qwen2.5-coder\",\n",
    "    # \"deepseek-r1\",   # here with no thinking\n",
    "    # \"deepseek-r1\",\n",
    "    # \"gemma3\",\n",
    "    # \"phi4-mini\",\n",
    "]\n",
    "\n",
    "model_thinking = [\n",
    "    False,\n",
    "    # False,\n",
    "    # True,\n",
    "    # False,\n",
    "    # False,\n",
    "    # False,\n",
    "    # False,\n",
    "    # True,\n",
    "    # False,\n",
    "    # False,\n",
    "    # False\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c7ab610",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = (\n",
    "    \"\"\"\n",
    "    You are an expert NLU annotator. Your job is to rate how plausible a candidate meaning (sense)\n",
    "    is for the HOMONYM used in the target sentence within the short story.\n",
    "\n",
    "    Return ONLY a single JSON object with one key: \"score\" and an integer value 1, 2, 3, 4 or 5.\n",
    "    Integer mapping:\n",
    "      1 = Definitely not\n",
    "      2 = Probably not\n",
    "      3 = Ambiguous / Unsure\n",
    "      4 = Probably yes\n",
    "      5 = Definitely yes\n",
    "\n",
    "    The response must be a JSON object and nothing else, for example: {{\"score\": 4}}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "USER_PROMPT = (\n",
    "    \"\"\"\n",
    "    [STORY]\n",
    "    {full_story_text}\n",
    "\n",
    "    [HOMONYM]\n",
    "    {homonym}\n",
    "\n",
    "    [CANDIDATE SENSE]\n",
    "    {sense_text}\n",
    "\n",
    "    [ADDITIONAL CONTEXT]\n",
    "    A DeBERTa model (Accuracy: {deberta_accuracy:.2f}, Spearman Correlation: {deberta_spearman:.2f}) predicted a score of {deberta_prediction:.2f} for this example.\n",
    "    You can use this information to guide your decision, but rely on your own judgment if the context strongly suggests otherwise.\n",
    "\n",
    "    [TASK]\n",
    "    Based on the STORY above, decide how plausible it is that the HOMONYM is used with the\n",
    "    CANDIDATE SENSE in the target sentence.\n",
    "\n",
    "    Return ONLY a single JSON object with one key \"score\" and an integer value (1-5)\n",
    "    as described by the system message. Example output: {{\"score\": 3}}\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc50137d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_full_story_text(item):\n",
    "    \"\"\"Compose the story text used as context for rating.\n",
    "\n",
    "    Uses `precontext`, `sentence`, and `ending` fields when available and joins them into a single string.\n",
    "    \"\"\"\n",
    "    fullstory = f\"{item.get('precontext', '')} {item.get('sentence', '')} {item.get('ending', '')}\"\n",
    "    return fullstory.strip()\n",
    "\n",
    "\n",
    "def create_message(item, deberta_pred, deberta_scores):\n",
    "    sense = f\"{item.get('judged_meaning', '')} as in \\\"{item.get('example_sentence', '')}\\\"\".strip()\n",
    "    homonym = item.get(\"homonym\", \"\")\n",
    "    full_story_text = create_full_story_text(item)\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": USER_PROMPT.format(\n",
    "            full_story_text=full_story_text,\n",
    "            homonym=homonym,\n",
    "            sense_text=sense,\n",
    "            deberta_accuracy=deberta_scores['accuracy'],\n",
    "            deberta_spearman=deberta_scores['spearman'],\n",
    "            deberta_prediction=deberta_pred\n",
    "        )},\n",
    "    ]\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8189a8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_JSON_FILE = \"../data/train.json\"\n",
    "DEV_JSON_FILE = \"../data/dev.json\"\n",
    "DEBERTA_PRED_FILE = \"../deberta-finetune-2/predictions.jsonl\"\n",
    "DEBERTA_SCORE_FILE = \"../deberta-finetune-2/score.json\"\n",
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Loads the json containing the dataset and return a pandas dataframe.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    # Transpose because the json is {id: {features...}, ...}\n",
    "    df = pd.DataFrame(data).T\n",
    "    # Ensure 'average' is float\n",
    "    df['average'] = df['average'].astype(float)\n",
    "    # Ensure 'choices' is list (for scoring later)\n",
    "    return df\n",
    "\n",
    "def load_deberta_results(pred_file, score_file):\n",
    "    with open(score_file, 'r') as f:\n",
    "        scores = json.load(f)\n",
    "    \n",
    "    preds = {}\n",
    "    with open(pred_file, 'r') as f:\n",
    "        for line in f:\n",
    "            item = json.loads(line)\n",
    "            preds[str(item['id'])] = item['prediction']\n",
    "            \n",
    "    return scores, preds\n",
    "\n",
    "df_train = load_data(TRAIN_JSON_FILE)\n",
    "df_dev = load_data(DEV_JSON_FILE)\n",
    "deberta_scores, deberta_preds = load_deberta_results(DEBERTA_PRED_FILE, DEBERTA_SCORE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30379453",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Score(BaseModel):\n",
    "    score: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afa993d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mresponse\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mmodel\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mqwen2.5-coder\u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mresponse\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mtotal_duration\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;245m*\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m10e-9\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m153.73313129000002\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mresponse\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mmessage\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mrole\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36massistant\u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mresponse\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mmessage\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mcontent\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36m{\u001b[39m\u001b[38;5;36m\"\u001b[39m\u001b[38;5;36mscore\u001b[39m\u001b[38;5;36m\"\u001b[39m\u001b[38;5;36m: 2}\u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mresponse\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mmessage\u001b[39m\u001b[38;5;245m.\u001b[39m\u001b[38;5;247mthinking\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;100mNone\u001b[39m\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mmessages\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;245m{\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mcontent\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m              \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36m    You are an expert NLU annotator. Your job is to rate how \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mplausible a candidate meaning (sense)\u001b[39m\n",
      "\u001b[38;5;245m              \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36m    is for the HOMONYM used in the target sentence within the \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mshort story.\u001b[39m\n",
      "\u001b[38;5;245m              \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m              \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36m    Return ONLY a single JSON object with one key: \u001b[39m\u001b[38;5;36m\"\u001b[39m\u001b[38;5;36mscore\u001b[39m\u001b[38;5;36m\"\u001b[39m\u001b[38;5;36m and \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36man integer value 1, 2, 3, 4 or 5.\u001b[39m\n",
      "\u001b[38;5;245m              \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36m    Integer mapping:\u001b[39m\n",
      "\u001b[38;5;245m              \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36m      1 = Definitely not\u001b[39m\n",
      "\u001b[38;5;245m              \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36m      2 = Probably not\u001b[39m\n",
      "\u001b[38;5;245m              \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36m      3 = Ambiguous / Unsure\u001b[39m\n",
      "\u001b[38;5;245m              \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36m      4 = Probably yes\u001b[39m\n",
      "\u001b[38;5;245m              \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36m      5 = Definitely yes\u001b[39m\n",
      "\u001b[38;5;245m              \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m              \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36m    The response must be a JSON object and nothing else, for \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mexample: \u001b[39m\u001b[38;5;36m{{\u001b[39m\u001b[38;5;36m\"\u001b[39m\u001b[38;5;36mscore\u001b[39m\u001b[38;5;36m\"\u001b[39m\u001b[38;5;36m: 4}}\u001b[39m\n",
      "\u001b[38;5;245m              \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36m    \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m,\u001b[39m\n",
      "\u001b[38;5;245m                \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mrole\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36msystem\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m}\u001b[39m\u001b[38;5;245m,\u001b[39m\n",
      "\u001b[38;5;245m               \u001b[39m\u001b[38;5;245m{\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mcontent\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m              \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36m    [STORY]\u001b[39m\n",
      "\u001b[38;5;245m              \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36m    James walked into the room, his eyes scanning the space \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mcarefully. On the table in the center lay a large, old book, \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36msurrounded by scattered papers. He approached it slowly, feeling \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36ma sense of anticipation. There was a good pile on it. He ran his \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mhands across it, enjoying the feeling.\u001b[39m\n",
      "\u001b[38;5;245m              \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m              \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36m    [HOMONYM]\u001b[39m\n",
      "\u001b[38;5;245m              \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36m    pile\u001b[39m\n",
      "\u001b[38;5;245m              \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m              \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36m    [CANDIDATE SENSE]\u001b[39m\n",
      "\u001b[38;5;245m              \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36m    a large sum of money (especially as pay or profit) as in \u001b[39m\u001b[38;5;36m\"\u001b[39m\u001b[38;5;36mHe \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mearned a nice pile selling stocks.\u001b[39m\u001b[38;5;36m\"\u001b[39m\n",
      "\u001b[38;5;245m              \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m              \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36m    [ADDITIONAL CONTEXT]\u001b[39m\n",
      "\u001b[38;5;245m              \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36m    A DeBERTa model (Accuracy: 0.82, Spearman Correlation: 0.69) \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mpredicted a score of 2.02 for this example.\u001b[39m\n",
      "\u001b[38;5;245m              \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36m    You can use this information to guide your decision, but \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mrely on your own judgment if the context strongly suggests \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36motherwise.\u001b[39m\n",
      "\u001b[38;5;245m              \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m              \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36m    [TASK]\u001b[39m\n",
      "\u001b[38;5;245m              \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36m    Based on the STORY above, decide how plausible it is that \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mthe HOMONYM is used with the\u001b[39m\n",
      "\u001b[38;5;245m              \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36m    CANDIDATE SENSE in the target sentence.\u001b[39m\n",
      "\u001b[38;5;245m              \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m              \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36m    Return ONLY a single JSON object with one key \u001b[39m\u001b[38;5;36m\"\u001b[39m\u001b[38;5;36mscore\u001b[39m\u001b[38;5;36m\"\u001b[39m\u001b[38;5;36m and an \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36minteger value (1-5)\u001b[39m\n",
      "\u001b[38;5;245m              \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36m    as described by the system message. Example output: \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36m{\u001b[39m\u001b[38;5;36m\"\u001b[39m\u001b[38;5;36mscore\u001b[39m\u001b[38;5;36m\"\u001b[39m\u001b[38;5;36m: 3}\u001b[39m\n",
      "\u001b[38;5;245m              \u001b[39m\u001b[38;5;36m'\u001b[39m\n",
      "\u001b[38;5;245m                           \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36m    \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m,\u001b[39m\n",
      "\u001b[38;5;245m                \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mrole\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36muser\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m}\u001b[39m\u001b[38;5;245m]\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': '\\n    You are an expert NLU annotator. Your job is to rate how plausible a candidate meaning (sense)\\n    is for the HOMONYM used in the target sentence within the short story.\\n\\n    Return ONLY a single JSON object with one key: \"score\" and an integer value 1, 2, 3, 4 or 5.\\n    Integer mapping:\\n      1 = Definitely not\\n      2 = Probably not\\n      3 = Ambiguous / Unsure\\n      4 = Probably yes\\n      5 = Definitely yes\\n\\n    The response must be a JSON object and nothing else, for example: {{\"score\": 4}}\\n    '},\n",
       " {'role': 'user',\n",
       "  'content': '\\n    [STORY]\\n    James walked into the room, his eyes scanning the space carefully. On the table in the center lay a large, old book, surrounded by scattered papers. He approached it slowly, feeling a sense of anticipation. There was a good pile on it. He ran his hands across it, enjoying the feeling.\\n\\n    [HOMONYM]\\n    pile\\n\\n    [CANDIDATE SENSE]\\n    a large sum of money (especially as pay or profit) as in \"He earned a nice pile selling stocks.\"\\n\\n    [ADDITIONAL CONTEXT]\\n    A DeBERTa model (Accuracy: 0.82, Spearman Correlation: 0.69) predicted a score of 2.02 for this example.\\n    You can use this information to guide your decision, but rely on your own judgment if the context strongly suggests otherwise.\\n\\n    [TASK]\\n    Based on the STORY above, decide how plausible it is that the HOMONYM is used with the\\n    CANDIDATE SENSE in the target sentence.\\n\\n    Return ONLY a single JSON object with one key \"score\" and an integer value (1-5)\\n    as described by the system message. Example output: {\"score\": 3}\\n    '}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random element in the dataset\n",
    "sample = df_dev.sample(1)\n",
    "idx = str(sample.index[0])\n",
    "item = sample.iloc[0].to_dict()\n",
    "\n",
    "# Get deberta prediction\n",
    "deberta_pred = deberta_preds.get(idx, 0.0)\n",
    "\n",
    "messages = create_message(item, deberta_pred, deberta_scores)\n",
    "\n",
    "model_number = 6  # change to try different models\n",
    "\n",
    "response: ChatResponse = chat(model=\"qwen2.5-coder\",\n",
    "                              messages=messages,\n",
    "                              think=False,\n",
    "                              format=Score.model_json_schema(),\n",
    "                              options={\n",
    "                                  \"temperature\": 0\n",
    "                              }\n",
    "                              )\n",
    "\n",
    "# ic(messages)\n",
    "ic(response.model)\n",
    "ic(response.total_duration * 10e-9)  # convert from ns to s\n",
    "ic(response.message.role)\n",
    "ic(response.message.content)\n",
    "ic(response.message.thinking)\n",
    "ic(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22c33ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dev_predictions(model_name, df, deberta_preds, deberta_scores, max_examples=None, think=False):\n",
    "    preds = []\n",
    "    failed_ids = []\n",
    "    ids = list(df.index.astype(str))\n",
    "    if max_examples is not None:\n",
    "        ids = ids[:max_examples]\n",
    "\n",
    "    total_start = time.perf_counter()\n",
    "    per_item_times = []\n",
    "\n",
    "    for idx in tqdm(ids):\n",
    "        item = df.loc[idx].to_dict()\n",
    "        \n",
    "        deberta_pred = deberta_preds.get(str(idx))\n",
    "        if deberta_pred is None:\n",
    "            print(f\"Warning: No DeBERTa prediction for id {idx}\")\n",
    "            deberta_pred = 0.0\n",
    "\n",
    "        messages = create_message(item, deberta_pred, deberta_scores)\n",
    "\n",
    "        start = time.perf_counter()\n",
    "        try:\n",
    "            response: ChatResponse = chat(model=model_name,\n",
    "                                          messages=messages,\n",
    "                                          think=think,\n",
    "                                          format=Score.model_json_schema(),\n",
    "                                          options={\n",
    "                                              \"temperature\": 0\n",
    "                                          }\n",
    "                                          )\n",
    "            elapsed = time.perf_counter() - start\n",
    "\n",
    "            per_item_times.append((idx, elapsed))\n",
    "\n",
    "            content = response.message.content\n",
    "            try:\n",
    "                s = Score.model_validate_json(content)\n",
    "                pred = int(s.score)\n",
    "                if pred < 1 or pred > 5:\n",
    "                    raise ValueError(\"score out of range\")\n",
    "            except Exception:\n",
    "                # Keep id of failed element so it can be removed from evaluation\n",
    "                print(\"Invalid JSON or missing/invalid score for item id:\", idx, \"content:\", content)\n",
    "                pred = None\n",
    "                failed_ids.append(str(idx))\n",
    "\n",
    "        except Exception as e:\n",
    "            elapsed = time.perf_counter() - start\n",
    "            print(f\"Error calling model {model_name} for id {idx}: {e}\")\n",
    "            pred = None\n",
    "            failed_ids.append(str(idx))\n",
    "            per_item_times.append((idx, elapsed))\n",
    "\n",
    "        preds.append({\"id\": str(idx), \"prediction\": pred, \"time\": elapsed})\n",
    "\n",
    "    total_elapsed = time.perf_counter() - total_start\n",
    "    # attach summary timings as metadata and failed ids\n",
    "    return {\n",
    "        \"predictions\": preds,\n",
    "        \"failed_ids\": failed_ids,\n",
    "        \"total_time\": total_elapsed,\n",
    "        \"per_item_times\": per_item_times,\n",
    "        \"avg_time\": sum(t for _, t in per_item_times) / len(per_item_times) if per_item_times else 0,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31ae9cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running model: llama3.1 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 588/588 [04:47<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to ../llm-ollama/zero-shot-deberta/llama3.1/predictions.jsonl\n",
      "Gold data saved to ../llm-ollama/zero-shot-deberta/llama3.1/ref.jsonl\n",
      "Timing saved to ../llm-ollama/zero-shot-deberta/llama3.1/timing.txt\n",
      "Importing...\n",
      "Starting Scoring script...\n",
      "Everything looks OK. Evaluating file ../llm-ollama/zero-shot-deberta/llama3.1/predictions.jsonl on ../llm-ollama/zero-shot-deberta/llama3.1/ref.jsonl\n",
      "----------\n",
      "Spearman Correlation: 0.5124590139763266\n",
      "Spearman p-Value: 1.0981397336641898e-40\n",
      "----------\n",
      "Accuracy: 0.7295918367346939 (429/588)\n",
      "Results dumped into scores.json successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[K\u001b[?25h\u001b[?2026l\u001b[2K\u001b[1G\u001b[?25h"
     ]
    }
   ],
   "source": [
    "for model_name, think in zip(model_names, model_thinking):\n",
    "    if think:\n",
    "        MAX_EXAMPLES = 100  # set to an int to limit samples per model\n",
    "    else:\n",
    "        MAX_EXAMPLES = None  # set to None for not thinking models\n",
    "\n",
    "    print(f\"\\n=== Running model: {model_name} ===\")\n",
    "\n",
    "    # If deepseek check if thinking to have different directoies\n",
    "    if think:\n",
    "        OUT_DIR = f\"../llm-ollama/zero-shot-deberta/{model_name.replace(':', '-')}-think\"\n",
    "        os.makedirs(OUT_DIR, exist_ok=True)\n",
    "    else:\n",
    "        OUT_DIR = f\"../llm-ollama/zero-shot-deberta/{model_name.replace(':', '-')}\"\n",
    "        os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "    # get predictions (may take a while if MAX_EXAMPLES is None)\n",
    "    # res = get_dev_predictions(model_name, df_dev, max_examples=MAX_EXAMPLES)\n",
    "    res = get_dev_predictions(model_name, df_dev, deberta_preds, deberta_scores, max_examples=MAX_EXAMPLES, think=think)\n",
    "\n",
    "    preds = res[\"predictions\"]\n",
    "\n",
    "    pred_file = os.path.join(OUT_DIR, \"predictions.jsonl\")\n",
    "    # Only write successful predictions (skip None) so pred/ref sizes are aligned\n",
    "    with open(pred_file, \"w\") as f:\n",
    "        for p in preds:\n",
    "            if p[\"prediction\"] is None:\n",
    "                # skip failed predictions (they are recorded in failed_ids)\n",
    "                continue\n",
    "            f.write(json.dumps({\"id\": p[\"id\"], \"prediction\": p[\"prediction\"]}) + \"\\n\")\n",
    "\n",
    "    # Save failed ids so they can be excluded from scoring\n",
    "    failed_file = os.path.join(OUT_DIR, \"failed_ids.jsonl\")\n",
    "    with open(failed_file, \"w\") as f:\n",
    "        for fid in res.get(\"failed_ids\", []):\n",
    "            f.write(json.dumps({\"id\": fid}) + \"\\n\")\n",
    "\n",
    "    # Save timing info and per-item times\n",
    "    timing_file = os.path.join(OUT_DIR, \"timing.txt\")\n",
    "    with open(timing_file, \"w\") as f:\n",
    "        f.write(f\"total_time_sec: {res['total_time']:.4f}\\n\")\n",
    "        f.write(f\"avg_time_sec: {res['avg_time']:.4f}\\n\")\n",
    "        f.write(\"per_item_times_sec:\\n\")\n",
    "        for idx, t in res[\"per_item_times\"]:\n",
    "            f.write(f\"{idx}: {t:.4f}\\n\")\n",
    "\n",
    "    # Create ref.jsonl from df_dev (respect MAX_EXAMPLES) inside the model folder\n",
    "    # Exclude any ids that failed JSON parsing so they won't be evaluated\n",
    "    failed_set = set(res.get(\"failed_ids\", []))\n",
    "    ref_file = os.path.join(OUT_DIR, \"ref.jsonl\")\n",
    "    with open(ref_file, \"w\") as f:\n",
    "        for idx, row in df_dev.iterrows():\n",
    "            if MAX_EXAMPLES is not None and int(idx) >= MAX_EXAMPLES:\n",
    "                break\n",
    "            if str(idx) in failed_set:\n",
    "                # skip items that produced invalid JSON for this model\n",
    "                continue\n",
    "            f.write(json.dumps({\"id\": str(idx), \"label\": row[\"choices\"]}) + \"\\n\")\n",
    "\n",
    "    print(f\"Predictions saved to {pred_file}\")\n",
    "    print(f\"Gold data saved to {ref_file}\")\n",
    "    print(f\"Timing saved to {timing_file}\")\n",
    "\n",
    "    # Sanity check: warn if counts differ\n",
    "    n_preds = sum(1 for _ in open(pred_file, \"r\"))\n",
    "    n_refs = sum(1 for _ in open(ref_file, \"r\"))\n",
    "    if n_preds != n_refs:\n",
    "        print(f\"Warning: #preds ({n_preds}) != #refs ({n_refs}). failed_ids_len={len(res.get('failed_ids', []))}\")\n",
    "\n",
    "    # If there is failed attemp rewrite all of the ids so that they are consecutive. This is needed for the scoring script\n",
    "    if len(res.get('failed_ids', [])) > 0:\n",
    "        # Rewrite pred_file with consecutive ids\n",
    "        new_pred_file = os.path.join(OUT_DIR, \"predictions_consecutive_ids.jsonl\")\n",
    "        with open(pred_file, \"r\") as fin, open(new_pred_file, \"w\") as fout:\n",
    "            for new_id, line in enumerate(fin):\n",
    "                obj = json.loads(line)\n",
    "                obj[\"id\"] = str(new_id)\n",
    "                fout.write(json.dumps(obj) + \"\\n\")\n",
    "        pred_file = new_pred_file\n",
    "\n",
    "        # Rewrite ref_file with consecutive ids\n",
    "        new_ref_file = os.path.join(OUT_DIR, \"ref_consecutive_ids.jsonl\")\n",
    "        with open(ref_file, \"r\") as fin, open(new_ref_file, \"w\") as fout:\n",
    "            for new_id, line in enumerate(fin):\n",
    "                obj = json.loads(line)\n",
    "                obj[\"id\"] = str(new_id)\n",
    "                fout.write(json.dumps(obj) + \"\\n\")\n",
    "        ref_file = new_ref_file\n",
    "\n",
    "    # Run scoring script for this model outputs\n",
    "    res = subprocess.run([\"python\", \"../score/scoring.py\", ref_file, pred_file, os.path.join(OUT_DIR, \"score.json\")], capture_output=True, text=True)\n",
    "    print(res.stdout)\n",
    "    if res.stderr:\n",
    "        print(\"Scoring STDERR:\")\n",
    "        print(res.stderr)\n",
    "\n",
    "    # \n",
    "    subprocess.run([\"ollama\", \"stop\", model_name], check=False)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0738daef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
